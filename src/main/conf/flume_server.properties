PREFIX="/opt/modules/flume-1.6.0"

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = avro
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 44444



# Test in memory
# Use a channel which buffers events in memory   （后面有file channel配置方案）
# a1.channels.c1.type = memory
# a1.channels.c1.capacity = 1000
# a1.channels.c1.transactionCapacity = 100

a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /opt/modules/flume-1.6.0/checkpoint
a1.channels.c1.useDualCheckpoints = true
a1.channels.c1.backupCheckpointDir =  /opt/modules/flume-1.6.0/backupcheckpoint
a1.channels.c1.dataDirs = /opt/modules/flume-1.6.0/data



# test sink local path
# Describe the sink （后面有hdfs方式）
# a1.sinks.k1.type = file_roll
# a1.sinks.k1.sink.directory = /tmp/test
# a1.sinks.k1.sink.rollInterval = 3600

a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = /flume/nginx/%Y%m%d
a1.sinks.k1.hdfs.rollInterval = 3600
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.rollSize = 0
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.sinks.k1.hdfs.filePrefix = access.DOMAIN
a1.sinks.k1.hdfs.inUseSuffix = .tmp
a1.sinks.k1.hdfs.idleTimeout = 300
# 在某文件空闲5分钟后自己释放



# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1


# Topic指定了多个分区,利用Flume拦截器（interceptors）实现Kafka Sink的自定义规则多分区写入
a1.sinks.k2.type = org.apache.flume.plugins.KafkaSink
a1.sinks.k2.metadata.broker.list=127.0.0.1:9092
a1.sinks.k2.partition.key=0
a1.sinks.k2.partitioner.class=org.apache.flume.plugins.SinglePartition
a1.sinks.k2.serializer.class=kafka.serializer.StringEncoder
a1.sinks.k2.request.required.acks=0
a1.sinks.k2.max.message.size=1000000
a1.sinks.k2.producer.type=async
a1.sinks.k2.custom.encoding=UTF-8
a1.sinks.k2.custom.topic.name=testToptic