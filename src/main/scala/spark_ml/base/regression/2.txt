本周重点：统计学中的回归.一元、二元线性回归为传统意义上的回归，logistic回归为线性回归，也可归为广义的线性回归。
什么是回归？
	回归分析就是利用样本（已知数据），产生拟合方程，从而（对未知数据）迚行预测。
	因为样本数据点本身就带有测量误差或一些客观因素产生的误差，
	所以如果拟合曲线严格通过样本数据点，就会带来过拟合问题，使得拟合模型难以推广。如果拟合曲线为直线，即为线性拟合。
	回归直线模型：  y=a+b*x，x--自变量， y--因变量，a、b--回归参数（需要通过数据样本点计算）
模型的作用：1）预测  2）判别合理性
回归分类：
	一元线性回归：自变量为1个，且为直线模型拟合。
	多元线性回归：自变量有多个，但回归方程仍为一次方程。此时拟合模型为一个平面或超平面（3维以上高维空间）。
	非线性回归：拟合曲线非直线，有部分非线性回归可以转化为线性求解，这些模型称为广义线性模型，例如logistic 回归。
回归问题的困难所在：
	选定变量（多元）（即降维），
	避免多重共线性（即去冗余，减小模型误差，重点如何发现多重共线性变量，如何去掉它），
	观察拟合方程，避免过度拟合，检验模型是否合理。
自变量和因变量关系：
	1）函数关系：确定性关系
	2）相关关系：非确定性关系，例如物理和化学成绩的关系。


一、 R语言中的一元回归：
	y=c(61,57,58,40,90,35,68)  #c是创建向量
	a=lm(y~1+x)       #lm为linear model的意思，或者写成 lm(y~x)；如果是 lm(y~x-1) 则所求模型过原点，即截距为0。
	summary(a)   #查看结果
	plot(x,y)  #直接画散点图
	residuals(a)  #求残差
	deviance(a) #求残差平方和
	print(a) #打印模型信息
	anova（a） #计算方差分析表
	z=data.frame(x=185)   #做预测，先要把自变量放在一个数据框中
	predict(a,z)
	coef（a） #求模型系数
	fomula（a） #提取模型公式

	用summary求出的线性模型汇总公式中各参数的含义
	结果中除了模型参数外，包括假设检验的结果。
	变量后对应的*越多越好
	Pr（>|t|）--反映t值以外的面积，越小越好，<0.05为'.'，<0.01为‘**’，...*越多否定意义越强，
	即假设越可能是不对的。p-value--假设所有系数为0，而进行的检验，值如果非常小，说明假设不合理，应该否定，即线性模型是合理的。


二、多元线性回归
	虚拟变量（哑变量）
	是回归里常用的技巧，主要用于离散变量（分类变量，R语言也成为因子变量）。

	举例：体重w与身高h、性别sex、人种color等因素有关，但sex、color不是连续型变量，是离散型的。
	对于sex，对应两个哑变量--isman、iswoman，如果是男人，isman为[1 0]', iswoman为[0 1]'。
	对于color，对应三个哑变量--isy、isw、isb，如果是黑人，isy、isw、isb分别为0 0  1.

哑变量回归方法：
	1）加法模型：将哑变量和原变量相加，
		例如 w=a+b*h+c*isman+d*isy+e*isw+f   （注意由于iswoman 和 isb 可以由其他哑变量推出，所以这里没有用）
		因为哑变量只能取0或1，所以不同的样本数据对应的加法模型，斜率都相同，只能影响w的截距（即a不同），
		也就是说哑变量起到调整回归模型截距的作用。

	2）乘法模型：
		例如，如果不考虑例子中的肤色，则   w=a+b*isman*h+d*iswoman*h +e
		（注意在乘法模型中必须写出各种可能性，所以这里对于性别，需要isman和iswoman两种哑变量体现）

	3）混合模型：
		例如，如果不考虑例子中的肤色，则 w=a+b*h+c*isman+d*iswoman +e*isman*h+f*iswoman*h +g
		上式既有加法项，也有乘法项，所以不同的样本对应的混合模型，斜率和截距都不同。

		举例：薛毅书R-modeling.pdf，P340的例6.9
		该例子中的改进都是凭数据分析师的经验来添减变量。而统计学中的“逐步回归”的方法就是用来选择变量的。

逐步回归
	1）向前引入法：从一元回归开始，逐步增加变量，使指标值达到最优为止
	2）向后剔除法：从全变量回归方程开始，逐步删去某个变量，使指标值达到最优为止
	3）逐步筛选法：综合上述两种方法

衡量一个模型好坏的指标
	1）残差平方和RSS---越小越好；
	2）相关系数平方R2---越大越接近1越好；
	3）赤池信息准则AIC---越小越好，
	AIC=n ln (RSSp/n)+2p，    n为变量总个数，p为选出的变量个数。

R语言中的逐步回归函数---step：  薛毅R-modelling.pdf的P347，其结果指标用AIC衡量。
举例：薛毅书R-modeling.pdf，P348的例6.10

三、回归诊断
回归诊断要回答的问题：
	1）样本是否符合正态分布假设？
		做线性回归的前提条件是假设样本为正态分布。
	2）是否存在离群值导致模型产生较大误差？
		离群值为偏离正常范围较大的样本测量值。
	3）线性模型是否合理？
	4）误差是否满足独立性、等方差、正态分布等假设条件？
		如果样本是正态分布，则误差也是正态分布，而且是独立、等方差的（即误差不会随因变量y大小变化而变化）。
	5）是否存在多重共线性？
		即自变量矩阵行列式或最小特征值接近于0，无法求逆。


正态分布检验
函数shapiro.test( )检验样本和样本所在整体是否符合正态分布。
	假设：样本符合正态分布。
	如果能否定该假设，说明样本不符合正态分布，不能使用线性回归方法。如果不能否定该假设，则可认为样本符合正态分布。
	p>0.05,正态分布

	举例：对数据框x中的自变量x1检验其是否符合正态分布
		shapiro.test(x$x1)  #x为三科成绩的数据框，x1为其中一科成绩
		结果  p-value=0.9259----------- p值较大，不能否定假设，即x1可看做是正态分布。

		shapiro.test(x$x3)
		结果  p-value=0.0003618 ----------p值小，说明统计学意义明显，应该拒绝假设，即x3不符合正态分布。
		*****如果正态分布的样本数据中存在连接值，即重复的样本值，则用该函数判断，可能会出现判断结果不是正态分布。
		解决方法：给每个样本数据加上一个非常小的随机扰动，这样既避免出现连接值，又不影响正态分布。



	举例：薛毅书R-modeling.pdf，P354的例6.11
		四个例子中分别针对线性回归时的不同问题，分析，并给出解决方案。

残差分析
	函数residuals()用于计算残差， 见薛毅书R-modeling.pdf，P358
	然后用shaoiro.test()检验残差是否符合正态分布。

画残差分布图：
	见薛毅书R-modeling.pdf，P361
	举例：iris鸢尾花数据
	>iris  #调入数据
	> z<-lm(iris$Sepal.Length~iris$Sepal.Width) #建立模型
	> plot(z) #画模型的各种残差图，点击鼠标左键，可看见不同的残差图。

多重共线性
产生原因：一些变量可通过另一些变量的组合来产生，则变量矩阵不可逆，从而引起模型有很大误差。
	如何发现和判断：见薛毅书R-modeling.pdf，P377
		通过判断变量矩阵X'X的条件数，即kappa值，R语言中函数为kappa(X)。
		如果kapp值<100则可排除多重共线性；如果kappa∈[100 1000]，则认为存在中等或较强的多重共线性；
		如果kappa>1000，则认为存在严重的多重共线性。

	举例：见薛毅书R-modeling.pdf，P378
	用特征根函数 eigen()求相关系数矩阵的最小特征根所对应的特征向量系数来判断。

广义线性模型
非线性回归无法直接用最小二乘法解。但其中有一类回归可以转变为线性回归。
	举例：见薛毅书R-modeling.pdf，P383 例6.19

四、非线性回归
	举例：销售额x和流通费率y的回归关系
	首先用线性回归，得到模拟的系数为***，但是R2不理想，所以否定线性模型。
	然后用非线性模型回归：
	1)假设对数模型y=a+b*log(x) 则用命令
		lm.log=lm(y~log(x))
		summary(lm.log)
		plot(x,y)
		lines(x,fitted(lm.log))
	2）假设指数模型y=a*ebx
		lm.exp=lm(log(y)~x)   #注意为了化成线性模型，给两边取了对数
		summary(lm.exp)
		plot(x,y)
		lines(x,exp(fitted(lm.exp)))

	3）假设幂函数模型y=a*xb
		lm.pow=lm(log(y)~log(x)) #同上面一样，两边取对数
		summary(lm.pow)
		plot(x,y)
		lines(x,exp(fitted(lm.pow)))

	4）假设二次多项式方程模型y=a+bx+cx2
		x1=x
		x2=x^2
		lm.2=lm(y~x1+x2)
		summary(lm.2)
		plot(x,y)
		lines(x,fitted(lm.2))

	对比以上各种拟合回归过程得出结论是最佳模型。
	理论上无论什么数据，都可以通过足够高阶次的多项式得到回归模型，但如果阶次过高，易造成过拟合。

非线性模型参数估计函数nls()

五、案例分析——预测网页流量
	使用互联网排名前1000的网站的数据  top_1000_sites.tsv
	Rank：排名
	PageViews：网站访问量
	UniqueVisitor：访问用户数目
	HasAdvertising：是否有广告
	IsEnglish：主要使用的语言是否为英语


参考:
http://f.dataguru.cn/thread-596270-1-1.html

虚拟变量 哑变量:
https://wenku.baidu.com/view/02bac09ca58da0116c1749de.html
http://blog.csdn.net/mousever/article/details/50500205
用R语言做正态分布检验
http://blog.csdn.net/mousever/article/details/51419077


回归结果的一般解释
http://blog.csdn.net/mousever/article/details/50511808

