bin/spark-submit --class com.study.spark.WordCount --master spark://hadoop:7010 /opt/app/jar/wordcount.jar


Spark是分布式,基于内存,特别适合迭代式计算的计算框架
基于内存(在一定情况下也会基于磁盘),业界验证spark可以适合各种规模,5-8000台,PB级别等,数据大于内存时候,会基于磁盘,这时候要注意放置策略和性能调优
一个技术堆栈解决所有大数据问题:
	交互式查询:Shell和spl方式.
	流处理
	批处理,内核基于rdd的编程
	同时还包含了机器学习,R,图计算等内容
	等其他模块,一栈式
理解spark:三个技术方面:
	1.分布式,多台机器运行,特征:整个spark有一个Driver端,提交给集群,集群中会有多个机器作为Executor,每个机器是一个节点,处理一部分数据,并行化,互补干扰.
	2.主要基于内存,spark优先考虑内存,因此速度会很快,
	3.迭代式计算,擅长迭代式计算是spark的真正精髓.stage1-->stage2-->starg3.
	基于内存计算比hadoop快100倍,基于磁盘计算比hadoop10倍
Spark Runtime
Dirver-->Worker,RAM,Input Data

开发spark:使用语言Scala和Java,Java理由:人才问题,与java ee等整合更加容易,维护更加容易
开发完Spark后在另一台机器上Driver,在Cluster中运行,处理数据来源: HDFS,HBase,Hive,DB,(Spark SQL只能取代hive的计算引擎Hive分为数据仓库和计算引擎),数据输出:HDFS,HBase,Hive,DB和Driver,Client端或者S3等.

RDD:弹性分布式数据集(DataSet):Rdd的数据会分片到很多机器节点上存储,默认优先放在具体内存中,弹性解析:
	弹性之一:自动的进行内存和磁盘数据存储的切换
	弹性之二:基于Lineage的高效容错,100个步骤91步骤上出错,可以从第90个步骤恢复
	弹性之三:Test如果失败会自动进行特定次数的重试(默认4次)
	弹性之四:stage如果失败会自动进行特定次数的重试,默认3次,并且只计算stage中失败的task

自动RDD做缓存时机:
	1.计算特别耗时
	2.计算链条很长
	3.shuffle之后
	4.checkpoint之前
	
RDD Operations
1.RDD创建
2.RDD Tansformation
3.RDD acrtion
4.RDD cache
================================================
复习:
spark核心RDD
RDD在saprk中是最基本,最重要的一个核心抽象概念(base abstraction)
RDD是一个不可改变的(immutable),分区(partitioned)的元素集合
RDD能够并行的(in parallel)进行操作
bin/spark-submit --class /opt/app/jar/wordcount.jar
	分区(a list of partitions)
	并行计算(a function for computing each split)
	依赖(a list of dependences on ather RDD)
	a Partitioner for key-value RDDs(is hash-partitioned)
	a list of preferred location(s) to compute each split on (block locations for an HDFS file)
	
==================================================
RDD create创建
bin/spark-shell 
a)从外部数据源,hadoop文件系统中读取
val rdd = sc.textFile("hdfs://hadoop:9000/user/spark/wc/input/data")
rdd.count
b)来自与本身的集合(parallelize并行化)
val rdd1 = sc.parallelize(List("a","b"))
val rdd2 = sc.parallelize(Array(1,2,3,4))
c)任意被hadoop支持的数据源,例如local file system,HDFS,Cassandra,Hbase,Amazon S3等
Spark支持 text files,SequenceFiles,和其他Hadoop的InputFormat

RDD Operations操作
----------------------------
RDD支持两种类型的操作:
1. 一个是(转换)transformations,能够创建一个新RDD数据集从一个已经存在的的rdd
例如wordcount:从一个RDD变为另外一个RDD
	文本text--->textfile("/..")-->RDD[String]//一行一行的数据--->flatMap(_.split(" "))-->RDD[(string,int)]//一个个的k-v --->reduceByKey((_+_))-->RDD[(String,Int)]
2. 还有一个是actions,action能够返回一个值给driver program通过对RDD进行计算

transformations不会真正执行,是懒执行操作
直到出现一个action触发计算,进行实际的数据处理.如:val rdd1 = sc.textFile("/..").flatMap(_.split(" "))map((_,1)).reduceBykey((_+_));以上均不会执行,只有rdd1.count,rdd1.collection等操作才会被真正执行
transformatcions在spark中是lazy的,意思是他们不会立即计算他们的结果,他们仅仅记住应用与基本数据集的transformations,.....
实例:
-------------------
常用的RDD Tansformation
map(func) ,
filter(func) ,过滤 func:_.contains(".."),_.startwith("..")
flatMap(func) ,_.split(" ") 序列化map
mapPartitions(func) ,mapPartitionsWithIndex(func) ,sample(withReplacement, fraction, seed) ,
union(otherDataset) ,合并 
intersection(otherDataset) ,
distinct([numTasks])) ,去除重复
groupByKey([numTasks]) ,分组
reduceByKey(func, [numTasks]) ,按照key进行reduce合并
aggregateByKey(zeroValue)(seqOp, combOp, [numTasks]) ,
sortByKey([ascending], [numTasks]) ,按照key进行sort
join(otherDataset, [numTasks]) ,加入,
cogroup(otherDataset, [numTasks]) ,cartesian(otherDataset) ,pipe(command, [envVars]) ,coalesce(numPartitions) ,repartition(numPartitions) , repartitionAndSortWithinPartitions(partitioner) 

常用的RDD action
reduce(func) ,例如:reduce((_+_))
collect() :转换成一个集合
count() 计数
first() 第一个元素
take(n) 返回n行/个元素
takeSample(withReplacement, num, [seed]) takeOrdered(n, [ordering]) saveAsTextFile(path) 文本文件保存
saveAsSequenceFile(path)(Java and Scala) 
saveAsObjectFile(path)(Java and Scala) 
countByKey() 对key进行count
foreach(func) 遍历
具体演示见spark-1
Shuffle operations

缓存RDD chache:将RDD缓存到内存当中去
cache方法是延迟执行的,需要讲RDD进行一个action时才执行
cache是persistent特殊缓存方式,将RDD放到内存中
rdd.chache
rdd.count()

