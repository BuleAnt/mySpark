TaskScheduler原理解密
TaskScheduler源码解密

一:TaskScheduler原理解密
	1.DAGScheduler在提交TaskSet给底层调度器的时候是面向接口TaskScheduler的,
		这符合面向对象中依赖抽象而不依赖具体的原则,带来底层资源调度器的可插拔性,导致Spark可以运行在众多的资源调度器模式上,
		例如Standalone,Yarn,Mesos,Local,EC2,以及其他自定义的资源调度器;
		在Standalone的模式下我们聚焦于TaskSchedulerImpl;
	
	2.在SparkContext实例化的时候通过CreateTaskScheduler来创建TaskSchedulerImpl和SparkDeploySchedulerBackend;
	SparkContext类:
	 private def createTaskScheduler(
	 master match {
	  case SPARK_REGEX(sparkUrl) =>
			val scheduler = new TaskSchedulerImpl(sc)
			val masterUrls = sparkUrl.split(",").map("spark://" + _)
			val backend = new SparkDeploySchedulerBackend(scheduler, sc, masterUrls)
			scheduler.initialize(backend)
			(backend, scheduler)

	在TaskSchedulerImpl的initialize方法中把SparkDeploySchedulerBackend传进来从而赋值为TaskSchedulerImpl的backend;
	在TaskSchedulerImpl调用start方法的时候,会调用backend.start方法,在start方法中会最终注册应用程序
	
	// Create and start the scheduler
    val (sched, ts) = SparkContext.createTaskScheduler(this, master)
    _schedulerBackend = sched
    _taskScheduler = ts
    _dagScheduler = new DAGScheduler(this)
    _heartbeatReceiver.ask[Boolean](TaskSchedulerIsSet)

    // start TaskScheduler after taskScheduler sets DAGScheduler reference in DAGScheduler's
    // constructor
    _taskScheduler.start()
	-->TaskSchedulerImpl.start()方法:
		override def start() {
		backend.start()
    	-->SparkDeploySchedulerBackend.start()方法:
			override def start() {
			....省略
			client = new AppClient(sc.env.rpcEnv, masters, appDesc, this, conf)
			client.start()
			-->AppClient.start方法中:
				def start() {
				// Just launch an rpcEndpoint; it will call back into the listener.
				endpoint.set(rpcEnv.setupEndpoint("AppClient", new ClientEndpoint(rpcEnv)))
				-->new ClientEndpoint(rpcEnv)
					 override def onStart(): Unit = {
						registerWithMaster(1)
					-->

	3.TaskScheduler的核心任务是提交TaskSet到集群运算并汇报结果,
		a)为TaskSet创建和维护一个TaskSetManager,并追踪任务本地性以及错误信息;
		b)遇到Straggle任务会放到其他的及节点进行重试;
		c)向DAGScheduler汇报执行情况,包括在Shuffle输出lost的时候报告fetch failed错误等信息;
	4.TaskScheduler内部会握有SchedulerBackend,从Standalone模式角度来讲具体实现是SparkDeploySchedulerBackend;
	5.SparkDeploySchedulerBackend在启动的时候会构造了AppClient实例,
	并在该实例start的时候启动了ClientEndpoint这个消息循环体,ClientEndpoint在启动时会向Master注册当前程序;

		SparkDeploySchedulerBackend类:
			def start(){
			.....
			client = new AppClient(sc.env.rpcEnv, masters, appDesc, this, conf)
			client.start()
			-->def start() {
			// Just launch an rpcEndpoint; it will call back into the listener.
			endpoint.set(rpcEnv.setupEndpoint("AppClient", new ClientEndpoint(rpcEnv)))
		  }
	
	而SparkDeploySchedulerBackend的父类CoarseGrainedSchedulerBackend,
	在start的时候会实例化类型DriverEndpoint(这就是我们程序运行时候经典的Driver)的消息循环体,

		CoarseGrainedSchedulerBackend类:
		内部类:
			 class DriverEndpoint(override val rpcEnv: RpcEnv, sparkProperties: Seq[(String, String)])
			extends ThreadSafeRpcEndpoint with Logging {

	SparkDeploySchedulerBackend专门负责收集Worker上的资源信息,
	当ExecutorBackend启动的时候会发送RegisteredExecutor信息向DriverEndpoint注册,
	此时SparkDeploySchedulerBackend就掌握了当前应用程序拥有的计算资源,
	TaskScheduler就通过SparkDeploySchedulerBackend拥有的计算资源来具体运行Task;

		override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit] = {
		  case RegisterExecutor(executorId, executorRef, hostPort, cores, logUrls) =>
		  ...
		 context.reply(RegisteredExecutor(executorAddress.host))

	6.SparkContext, DAGScheduler, TaskSchedulerImpl, SparkDeploySchedulerBackend
	在应用程序启动的时候只实例化一次,应用程序存在期间始终存在这些对象;
	
大总结:
	在SparkContext实例化的时候调用createTaskScheduler来创建TaskSchedulerImpl和SparkDeployBackend,
	同时在SparkContext实例化的时候会调用TaskSchedulerImpl的start,
		在start方法中会调用SparkDeploySchedulerBackend的start,
			在该start方法中会创建AppClient对象并调用AppClient对象的start方法,
			在该Start方法中会创建ClientEndpoint,
	在创建ClientEndpoint会传入Command来指定具体当前应用程序的Executor进程的入口的名称为CoarseGrainedExecutorBackend,
		然后ClientEndpoint启动并通过tryRegistermaster来注册当前的应用程序到Master中,
	Master接受到注册信息后如何可以运行程序,则会为该程序生成Job ID并通过schedule来分配计算资源,
		具体计算资源的分配是通过应用程序的运行方式,Memory,cores等配置信息来决定的,
	最后Master会发送指令给Worker,Worker中为当前应用程序分配计算资源时会首先分配ExecutorRunner,
	ExecutorRunner内部会通过Thread的方式构建ProcessBuilder来启动另外一个JVM进程,
		这个JVM进程启动时候加载的main方法所在的类的名称就是:
		在创建ClientEndpoint时传入的Command来指定具体名称为CoarseGrainedExecutorBackend的类,
		此时JVM在通过ProcessBuilder启动的时候获得了CoarseGrainedExecutorBackend后加载并调用其中的main方法,
		在main方法中会实例化CoarseGrainedExecutorBackend本身这个消息循环体,
	而CoarseGrainedExecutorBackend在实例化的时候会通过回调onStart,
		向DriverEndpoint发送RegisterExecutor来注册当前CoarseGrianedExecutorBackend,
	此时DriverEndpoint收到该注册信息并保存了SparkDeploySchedulerBackend实例的内存数据结构中,这样Driver就获得了计算资源!
	
概括图以及流程循环步骤如下:
	SparkContext{
	createTaskScheduler-->TaskSchedulerImpl,SparkDeploySchedulerBackend
	TaskSchedulerImpl.start-->SparkDeploySchedulerBackend.start:
	其中树形图如下:
		TaskSchedulerImpl{
			SparkDeployDeploySchedulerBackend[
				GoarseGrainedSchedulerBackend(
					DirverEndpoint;
					AppClient(ClientEndpoint:
						start-->SparkDeploySchedulerBackend.start
						-->new AppClient().start-->new ClientEndpoint(Command){
						Command:指定具体单签应用程序的Executor进行的入口类的名称:CoarseGrainedExecutorBackend;
						tryRegisterMaster():注册当前的应用程序到Master
					)
				)
			]
		}
然后:
Master:
	接受ClientEndpoint的注册信息后,运行程序
	-->为程序生成Job ID;通过schedule分配计算资源:通过运行方式,Memory,cores等配置信息来决定
	-->Master发送指令给Worker

Worker[ExecutorRunner]:
	为程序分配计算资源时,分配ExecutorRunner
	-->ExecutorRunner通过Thread方式构建ProcessBuilder
	-->启动另外一个JVM进程Executor

Executor:通过ThreadPool通过线程复用的方式并发执行Task

JVM启动:
	加载创建ClientEndpoint时传入Command指定的类即CoarseGrainedExecutorBackend类main()
	-->实例化CoarseGrainedExecutorBackend本身
	-->回调onStart():向DriverEndpoint发送RegisterExecutor来注册当前CoarseGrainedExecutorBackend-->

DriverEndpoint:
	收到注册信息并保存在SparkDeploySchedulerBackend实例的内存数据结构
	-->Driver获得了计算资源,同时发送RegisteredExecutor给CoarseGrainedExecutorBackend
	
CoarseGrainedExecutorBackend:收到RegisteredExecutor,通过Executor执行Task

