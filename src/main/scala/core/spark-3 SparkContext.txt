Spark内核分析
	1、编程模型
    2、DAG Scheduler
    3、Task Scheduler
    4、RDD、SparkContext源码解析
==================================
1.编程模型
打开ide工具
启动hadoop,启动spark

spark有一个driver program包含main函数,一个map,一系列的executor;main方法中有一个spark上下文SparkContext
SparkContext
val rdd = sc.textFile("/").flatMap(_.split(" ")).map(_ =>(_,1)).reduceByKey(_ + _)
rdd.collect
以上代码将在executor中执行,
一个Spark program的第一件事情就是创建SparkContext对象,它将告诉Spark如何获取一个集群,创建SparkContext必须先创建SparkConf对象,它包含一些关于app的信息
val conf = new SparkConf().setAppName(appName).setMaster(master)
new SparkContext(conf)
the appName参数是app在cluster UI中显示的名称,master可以是 Spark, Mesos or YARN cluster URL,或者local运行本地模式,当把app运行在cluster上时,你不需要在程序中编写master的代码,而是使用spark-submit来加载app,然而,对于本地测试,可以使用"local"来运行Spark程序

DAG Scheduler
--------------------------------
sc.textFile("/").flatMap(_.split(" ")).map(_ =>(_,1)).reduceByKey(_ + _).collect
1. RDD Object
	rdd.join(rdd2).groupBy(...).filter(...)-->build operator DAG
	在RDD Object阶段,构建一个有方向的rdd图,逆向的,按照依赖关系,构建一个DAG图,然后对DAG图进行调度,每一个-->表示一个操作
	比如如下:(rdd1 join rdd2)-->(groupBy)-->rdd3-->(filter)-->rdd4
	rdd1-->
	rdd2-->rdd3-->rdd4
2. DAG Scheduler
	将RDD的DAG图进行调度即为DAG Scheduler,这里分为很多阶段Stage
	Stage:例如RDD的DAG图中,单个rdd1-->rdd3和rdd2-->rdd3叫做一个阶段,rdd3-->rdd4一个阶段,也就是join是一个Stage,groupBy是一个Stage,filter是一个Stage
	Task概念:在rdd1-->rdd3阶段,会有很多个task,每个RDD有很多分片split,这些分片将分别转换到rdd3的各个split中,这个过程类似于map-reduce的shuffle过程,这样一个split经过转换发送到下一个rdd的split,每一个split的任务叫做一个task,如此这将DAG图划分成一系列的Task,Task是DAG最小单元
	Stage:在发生shuffle的时候,讲被划分为两个阶段,上一个rdd的分片形成下一个rdd对应的片为一个Stage,下一个rdd对上一个rdd发送过来的分片进行groupBy合并转换是另一个Stage,然后对整体进行filter的过程又是一个Stage.
4. Task Scheduler
	Task Scheduler是对各个阶段中的task进行调度,每个阶段的任务称为TaskSet,Task Scheduler会加载每个Task通过cluster manager
5. Worker
	最后Task将会被放在Worker中的通过Threads的Executor进行execute tasks,存储blocks.

容错:
	如果某个任务运行失败,在第4步中,通过Task Scheduler进行重试失败的
	rdd.chache
	rdd.doCheckpoint()
	sc.setCheckpointDir("/...")

