Spark Streaming基于kafka的Direct详解
SparkStreaming on Kafka Direct工作原理机制/案例/源码解析

一：SparkStreaming on Kafka Direct工作原理机制：
1、Direct方式特点：
	（1）Direct的方式是会直接操作kafka底层的元数据信息，
		这样如果计算失败了，可以把数据重新读一下，重新处理。
		即数据一定会被处理。拉数据，是RDD在执行的时候直接去拉数据。
	（2）由于直接操作的是kafka，kafka就相当于你底层的文件系统。
		这个时候能保证严格的事务一致性，即一定会被处理，而且只会被处理一次。
		而Receiver的方式则不能保证，因为Receiver和ZK中的数据可能不同步，
			Spark Streaming可能会重复消费数据，这个调优可以解决，但显然没有Direct方便。
		而Direct api直接是操作kafka的，
			spark streaming自己负责追踪消费这个数据的偏移量或者offset，并且自己保存到checkpoint，
			所以它的数据一定是同步的，一定不会被重复。即使重启也不会重复，因为checkpoint了，
		但是程序升级的时候，不能读取原先的checkpoint，面对升级checkpoint无效这个问题，怎么解决呢?
			升级的时候读取我指定的备份就可以了，即手动的指定checkpoint也是可以的，这就再次完美的确保了事务性，有且仅有一次的事务机制。
		那么怎么手动checkpoint呢？
			构建SparkStreaming的时候，有getorCreate这个api，它就会获取checkpoint的内容，具体指定下这个checkpoint在哪就好了。
			或者如下：
			private static JavaStreamingContext createContext(
			            String checkpointDirectory, SparkConf conf) {
			        System.out.println("Creating new context");

			        SparkConf sparkConf = conf;
			        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf,Durations.seconds(5));
			        ssc.checkpoint(checkpointDirectory);
			        return ssc;
			    }
			而如果从checkpoint恢复后，如果数据累积太多处理不过来，怎么办?
				1）限速
				2）增强机器的处理能力
				3）放到数据缓冲池中。

	（3）由于底层是直接读数据，没有所谓的Receiver，直接是周期性(Batch Intervel)的查询kafka，
		处理数据的时候，我们会使用基于kafka原生的Consumer api来获取kafka中特定范围(offset范围)中的数据。
		这个时候，Direct Api访问kafka带来的一个显而易见的性能上的好处就是，
			如果你要读取多个partition，Spark也会创建RDD的partition，这个时候RDD的partition和kafka的partition是一致的。
			而Receiver的方式，这2个partition是没任何关系的。
		这个优势是你的RDD，其实本质上讲在底层读取kafka的时候，kafka的partition就相当于原先hdfs上的一个block。
		这就符合了数据本地性:
			RDD和kafka数据都在这边。所以读数据的地方，处理数据的地方和驱动数据处理的程序都在同样的机器上，这样就可以极大的提高性能。
		不足之处是由于RDD和kafka的patition是一对一的，想提高并行度就会比较麻烦。
			提高并行度还是repartition，即重新分区，因为产生shuffle，很耗时。
			这个问题，以后也许新版本可以自由配置比例，不是一对一。
			因为提高并行度，可以更好的利用集群的计算资源，这是很有意义的。
	（4）不需要开启wal机制，
		从数据零丢失的角度来看，极大的提升了效率，还至少能节省一倍的磁盘空间。
		从kafka获取数据，比从hdfs获取数据快，因为zero copy的方式，速度肯定更快。

2、SparkStreaming on Kafka Direct与Receiver 的对比：
	从高层次的角度看，之前的和Kafka集成方案（reciever方法）使用WAL工作方式如下：
	1）使用Kafka高层消费者API
		运行在Spark workers/executors上的Kafka Receivers连续不断地从Kafka中读取数据，其中用到了Kafka中高层次的消费者API。
	2）Spark开启WALs
		接收到的数据被存储在Spark workers/executors中的内存，同时也被写入到WAL中。
		只有接收到的数据被持久化到log中，Kafka Receivers才会去更新Zookeeper中Kafka的偏移量。
	3）只能做到至少一次的语义
		接收到的数据和WAL存储位置信息被可靠地存储，如果期间出现故障，这些信息被用来从错误中恢复，并继续处理数据。这个方法可以保证从Kafka接收的数据不被丢失。
		但是在失败的情况下，有些数据很有可能会被处理不止一次！
		这种情况在一些接收到的数据被可靠地保存到WAL中，但是还没有来得及更新Zookeeper中Kafka偏移量，系统出现故障的情况下发生。
		这导致数据出现不一致性：Spark Streaming知道数据被接收，但是Kafka那边认为数据还没有被接收，这样在系统恢复正常时，Kafka会再一次发送这些数据。

		这种不一致产生的原因是因为两个系统无法对那些已经接收到的数据信息保存进行原子操作。
		为了解决这个问题，只需要一个系统来维护那些已经发送或接收的一致性视图，而且，这个系统需要拥有从失败中恢复的一切控制权利。
		基于这些考虑，社区决定将所有的消费偏移量信息只存储在Spark Streaming中，并且使用Kafka的低层次消费者API来从任意位置恢复数据。
	Direct API
		为了构建这个系统，新引入的Direct API采用完全不同于Receivers和WALs的处理方式。
		它不是启动一个Receivers来连续不断地从Kafka中接收数据并写入到WAL中，而且简单地给出每个batch区间需要读取的偏移量位置，
		最后，每个batch的Job被运行，那些对应偏移量的数据在Kafka中已经准备好了。
		这些偏移量信息也被可靠地存储（checkpoint），在从失败中恢复可以直接读取这些偏移量信息。

		需要注意的是，Spark Streaming可以在失败以后重新从Kafka中读取并处理那些数据段。
		然而，由于仅处理一次的语义，最后重新处理的结果和没有失败处理的结果是一致的。

	因此，Direct API消除了需要使用WAL和Receivers的情况，而且确保每个Kafka记录仅被接收一次并被高效地接收。
		这就使得我们可以将Spark Streaming和Kafka很好地整合在一起。
		总体来说，这些特性使得流处理管道拥有高容错性，高效性，而且很容易地被使用。

二、SparkStreaming on Kafka Direct 案例实战：
	See: SparkStreamingOnKafkaDirect.java
	接下来的步骤为：
	（1）首先在安装了zookeeper机器上的bin目录下启动zookeeper服务：
	（2）接下来在各个机器上启动Kafka服务，在Kafkabin目录下：
		1) nohup ./kafka-server-start.sh ../config/server.properties &
		2) ./kafka-topic.sh –create –zookeeper Master:2181,Worker1:2181,Worker2:2181 –replication-factor 3 –pertitions 1 –topic SaprkStreamingDirected
		3) ./kafka -console -producer.sh –broker-list Master:9092,Worker1:9092,Worker2:9092 –topic SparkStreamingDirected
	（3)在控制台上输入数据
	（4）此时你就可以在eclipse控制台上观察到值

三、SparkStreaming on Kafka Direct源码解析
	1、首先我们在KafkaUtils中看到createDirectStream的源码注释写的非常的纤细，
		主要包括你可以访问offset，怎样访问offset，通过foreach暴露我们需要的RDD等等

	2、在这里我们可以看到各个参数信息说明的非常详细：

	3、我们看到创建了DirectKafkaInputStream

	4、在DirectKafakaInputStream中我们可以看到它创建了DirectKafkaInputDStreamcheckpointData:

	5、通过DirectKafkaInputDStreamcheckpointData，这里我们可以看到，我们可以自定义checkpoint:

更多源码希望大家自己去看。
