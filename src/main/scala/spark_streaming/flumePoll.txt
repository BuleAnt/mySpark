Spark Streaming从Flume Poll数据案例实战和内幕源码解密

1、Spark Streaming on Polling from Flume实战
2、Spark Streaming on Polling from Flume源码

一、推模式(Flume push SparkStreaming)与拉模式（SparkStreaming poll Flume）比较 ：

采用推模式：推模式的理解就是Flume作为缓存，存有数据。监听对应端口，如果服务可以链接，就将数据push过去。(简单，耦合要低)，缺点是SparkStreaming 程序没有启动的话，Flume端会报错，同时可能会导致Spark Streaming 程序来不及消费的情况。
采用拉模式：拉模式就是自己定义一个sink，SparkStreaming自己去channel里面取数据，根据自身条件去获取数据，稳定性好。

二、Flume poll 实战：

1.Flume poll 配置

进入http://spark.apache.org/docs/latest/streaming-flume-integration.html官网，下载
spark-streaming-flume-sink_2.10-1.6.0.jar、scala-library-2.10.5.jar、commons-lang3-3.3.2.jar三个包：
这里写图片描述

2、将下载后的三个jar包放入Flume安装lib目录：

3、配置Flume conf环境参数：
首先进入此入境
这里写图片描述
接下来在此文件中的sink1中添加此内容：

agent1.sinks.sink1.type = org.apache.spark.streaming.flume.sink.SparkSink
agent1.sinks.sink1.hostname = Master
agent1.sinks.sink1.port = 9999
agent1.sinks.sink1.channel = channel1
三、编写代码：

启动HDFS集群：
启动运行Flume：
启动eclipse下的应用程序：

copy测试文件hellospark.txt到Flume flume-conf.properties配置文件中指定的/usr/local/flume/tmp/TestDir目录下：
隔24秒后可以在eclipse程序控制台中看到上传的文件单词统计结果。

四：源码分析：

1、创建createPollingStream （FlumeUtils.scala ）：
2、参数配置：默认的全局参数，private 级别配置无法修改：
这里写图片描述

3、创建FlumePollingInputDstream对象

这里写图片描述

4、继承自ReceiverInputDstream并覆写getReciver方法，调用FlumePollingReciver接口：

这里写图片描述

5、ReceiverInputDstream 构建了一个线程池，设置为后台线程；并使用lazy和工厂方法创建线程和NioClientSocket（NioClientSocket底层使用NettyServer的方式）

这里写图片描述

6、receiverExecutor 内部也是线程池；connections是指链接分布式Flume集群的FlumeConnection实体句柄的个数，线程拿到实体句柄访问数据。

这里写图片描述

7、启动时创建NettyTransceiver，根据并行度(默认5个)循环提交FlumeBatchFetcher

这里写图片描述

8、FlumeBatchFetcher run方法中从Receiver中获取connection链接句柄ack跟消息确认有关

这里写图片描述

9、获取一批一批数据方法

这里写图片描述

补充说明：

使用Spark Streaming可以处理各种数据来源类型，如：数据库、HDFS，服务器log日志、网络流，其强大超越了你想象不到的场景，只是很多时候大家不会用，其真正原因是对Spark、spark streaming本身不了解。